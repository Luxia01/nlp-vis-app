import streamlit as st

# åˆå§‹åŒ– session_state
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False
if "username" not in st.session_state:
    st.session_state.username = ""

# ç™»å½•å‡½æ•°
def login():
    st.title("ğŸ” ç™»å½• NLP å¯è§†åŒ–ç³»ç»Ÿ")
    username = st.text_input("ç”¨æˆ·å")
    password = st.text_input("å¯†ç ", type="password")
    login_btn = st.button("ç™»å½•")
    
    if login_btn:
        if username == "liming" and password == "123456":
            st.session_state.authenticated = True
            st.session_state.username = username
            st.success("ç™»å½•æˆåŠŸï¼è¯·ç‚¹å‡»å·¦ä¸Šè§’ [é‡æ–°è¿è¡Œ] æˆ–åˆ·æ–°é¡µé¢è¿›å…¥ç³»ç»Ÿ")
        else:
            st.error("ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")

# ç™»å½•æ§åˆ¶é€»è¾‘
if not st.session_state.authenticated:
    login()
    st.stop()

import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import matplotlib.pyplot as plt

# è®¾ç½®é¡µé¢
st.set_page_config(page_title="DistilBERT æƒ…æ„Ÿåˆ†æå¯è§†åŒ–", layout="centered")
st.title("ğŸŒŸ åŸºäº DistilBERT çš„æ–‡æœ¬æƒ…æ„Ÿåˆ†æå¯è§†åŒ–ç³»ç»Ÿ")

# æ–‡æœ¬è¾“å…¥
text = st.text_input("è¯·è¾“å…¥ä¸€å¥æ–‡æœ¬ï¼š", "æˆ‘çœŸçš„éå¸¸å–œæ¬¢è¿™éƒ¨ç”µå½±ï¼")

# ç¼“å­˜æ¨¡å‹åŠ è½½
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")
    model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")
    return tokenizer, model

tokenizer, model = load_model()

# æ‰§è¡Œåˆ†æ
if st.button("å¼€å§‹åˆ†æ"):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    outputs = model(**inputs)
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1).squeeze()

    labels = ["æ¶ˆæ", "ç§¯æ"]
    pred_label = labels[probs.argmax().item()]

    st.subheader("ğŸ§¾ æ¨¡å‹è¾“å‡ºç»“æœ")
    st.write(f"**é¢„æµ‹æ ‡ç­¾ï¼š** {pred_label}")
    st.write(f"**åˆ†ç±»æ¦‚ç‡ï¼š** {probs.tolist()}")

    # æ¡å½¢å›¾å±•ç¤º
    st.subheader("ğŸ“Š åˆ†ç±»æ¦‚ç‡å›¾")
    fig, ax = plt.subplots()
    ax.bar(labels, probs.tolist(), color=["red", "green"])
    ax.set_ylim([0, 1])
    st.pyplot(fig)

    # æ¨¡æ‹Ÿ Attention é«˜äº®ï¼ˆå¯è§†åŒ–ç¤ºä¾‹ï¼‰
    st.subheader("ğŸ§  æ¨¡æ‹Ÿ Attention é«˜äº®")
    tokens = tokenizer.tokenize(text)
    importance = torch.rand(len(tokens))  # æ¨¡æ‹Ÿæ³¨æ„åŠ›å¼ºåº¦
    highlighted = ""
    for token, score in zip(tokens, importance):
        opacity = round(float(score), 2)
        token_clean = token.replace("##", "")
        highlighted += f"<span style='background-color: rgba(255,255,0,{opacity}); padding:2px'>{token_clean}</span> "
    st.markdown(highlighted, unsafe_allow_html=True)



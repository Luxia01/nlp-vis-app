import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import matplotlib.pyplot as plt

# è®¾ç½®é¡µé¢
st.set_page_config(page_title="DistilBERT æƒ…æ„Ÿåˆ†æå¯è§†åŒ–", layout="centered")
st.title("ğŸŒŸ åŸºäº DistilBERT çš„æ–‡æœ¬æƒ…æ„Ÿåˆ†æå¯è§†åŒ–ç³»ç»Ÿ")

# æ–‡æœ¬è¾“å…¥
text = st.text_input("è¯·è¾“å…¥ä¸€å¥æ–‡æœ¬ï¼š", "æˆ‘çœŸçš„éå¸¸å–œæ¬¢è¿™éƒ¨ç”µå½±ï¼")

# ç¼“å­˜æ¨¡å‹åŠ è½½
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")
    model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")
    return tokenizer, model

tokenizer, model = load_model()

# æ‰§è¡Œåˆ†æ
if st.button("å¼€å§‹åˆ†æ"):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    outputs = model(**inputs)
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1).squeeze()

    labels = ["æ¶ˆæ", "ç§¯æ"]
    pred_label = labels[probs.argmax().item()]

    st.subheader("ğŸ§¾ æ¨¡å‹è¾“å‡ºç»“æœ")
    st.write(f"**é¢„æµ‹æ ‡ç­¾ï¼š** {pred_label}")
    st.write(f"**åˆ†ç±»æ¦‚ç‡ï¼š** {probs.tolist()}")

    # æ¡å½¢å›¾å±•ç¤º
    st.subheader("ğŸ“Š åˆ†ç±»æ¦‚ç‡å›¾")
    fig, ax = plt.subplots()
    ax.bar(labels, probs.tolist(), color=["red", "green"])
    ax.set_ylim([0, 1])
    st.pyplot(fig)

    # æ¨¡æ‹Ÿ Attention é«˜äº®ï¼ˆå¯è§†åŒ–ç¤ºä¾‹ï¼‰
    st.subheader("ğŸ§  æ¨¡æ‹Ÿ Attention é«˜äº®")
    tokens = tokenizer.tokenize(text)
    importance = torch.rand(len(tokens))  # æ¨¡æ‹Ÿæ³¨æ„åŠ›å¼ºåº¦
    highlighted = ""
    for token, score in zip(tokens, importance):
        opacity = round(float(score), 2)
        token_clean = token.replace("##", "")
        highlighted += f"<span style='background-color: rgba(255,255,0,{opacity}); padding:2px'>{token_clean}</span> "
    st.markdown(highlighted, unsafe_allow_html=True)



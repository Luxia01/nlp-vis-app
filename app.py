import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import matplotlib.pyplot as plt

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="ALBERT å¯è§†åŒ–ç³»ç»Ÿ", layout="centered")

st.title("ğŸŒŸ åŸºäº ALBERT çš„æ–‡æœ¬æƒ…æ„Ÿåˆ†æå¯è§†åŒ–ç³»ç»Ÿ")

# æ–‡æœ¬è¾“å…¥
text = st.text_input("è¯·è¾“å…¥ä¸€å¥æ–‡æœ¬ï¼š", "æˆ‘çœŸçš„éå¸¸å–œæ¬¢è¿™éƒ¨ç”µå½±ï¼")

# ç¼“å­˜æ¨¡å‹åŠ è½½
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("textattack/albert-base-v2-SST-2")
    model = AutoModelForSequenceClassification.from_pretrained("textattack/albert-base-v2-SST-2")
    return tokenizer, model

tokenizer, model = load_model()

# åˆ†ææŒ‰é’®
if st.button("å¼€å§‹åˆ†æ"):
    inputs = tokenizer(text, return_tensors="pt")
    outputs = model(**inputs)
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1).squeeze()
    labels = ["æ¶ˆæ", "ç§¯æ"]
    pred_label = labels[probs.argmax().item()]

    st.subheader("ğŸ§¾ æ¨¡å‹è¾“å‡ºç»“æœ")
    st.write(f"**é¢„æµ‹æ ‡ç­¾ï¼š** {pred_label}")
    st.write(f"**åˆ†ç±»æ¦‚ç‡ï¼š** {probs.tolist()}")

    # æ¦‚ç‡æ¡å½¢å›¾
    st.subheader("ğŸ“Š åˆ†ç±»æ¦‚ç‡å›¾")
    fig, ax = plt.subplots()
    ax.bar(labels, probs.tolist(), color=["red", "green"])
    ax.set_ylim([0, 1])
    st.pyplot(fig)

    # Attention é«˜äº®ï¼ˆæ¨¡æ‹Ÿæ•ˆæœï¼‰
    st.subheader("ğŸ§  æ¨¡å‹å…³æ³¨è¯ï¼ˆæ¨¡æ‹Ÿ Attention é«˜äº®ï¼‰")
    tokens = tokenizer.tokenize(text)
    importance = torch.rand(len(tokens))  # ä½¿ç”¨éšæœºæ•°æ¨¡æ‹Ÿæƒé‡

    highlighted = ""
    for token, score in zip(tokens, importance):
        opacity = round(float(score), 2)
        token_clean = token.replace("â–", "")
        highlighted += f"<span style='background-color: rgba(255,255,0,{opacity}); padding:2px'>{token_clean}</span> "

    st.markdown(highlighted, unsafe_allow_html=True)

